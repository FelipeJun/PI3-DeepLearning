{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "192 dados de entrada\n",
    "99 dados de saida (especies de planta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>Magnolia_Salicifolia</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152340</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Quercus_Canariensis</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>Quercus_Rubra</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.036133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>Quercus_Brantii</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.074219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>Salix_Fragilis</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.19238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
       "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
       "5   8   Magnolia_Salicifolia  0.070312  0.093750  0.033203  0.001953   \n",
       "6  10    Quercus_Canariensis  0.021484  0.031250  0.017578  0.009766   \n",
       "7  11          Quercus_Rubra  0.000000  0.000000  0.037109  0.050781   \n",
       "8  14        Quercus_Brantii  0.005859  0.001953  0.033203  0.015625   \n",
       "9  15         Salix_Fragilis  0.000000  0.000000  0.009766  0.037109   \n",
       "\n",
       "    margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
       "1  0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
       "2  0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
       "3  0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
       "4  0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
       "5  0.000000  0.152340  0.007812      0.0  ...   0.145510   0.000000   \n",
       "6  0.001953  0.042969  0.039062      0.0  ...   0.085938   0.000000   \n",
       "7  0.003906  0.000000  0.003906      0.0  ...   0.038086   0.025391   \n",
       "8  0.001953  0.000000  0.023438      0.0  ...   0.000000   0.000000   \n",
       "9  0.072266  0.000000  0.000000      0.0  ...   0.000000   0.000000   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156    0.00000   0.000000   0.004883   \n",
       "1   0.000000   0.000977   0.023438    0.00000   0.000000   0.000977   \n",
       "2   0.005859   0.000977   0.007812    0.00000   0.000000   0.000000   \n",
       "3   0.000000   0.000000   0.020508    0.00000   0.000000   0.017578   \n",
       "4   0.021484   0.000000   0.000000    0.00000   0.000000   0.000000   \n",
       "5   0.041992   0.000000   0.005859    0.00000   0.000000   0.000000   \n",
       "6   0.040039   0.000000   0.009766    0.00000   0.000000   0.000000   \n",
       "7   0.009766   0.002930   0.021484    0.00000   0.037109   0.006836   \n",
       "8   0.008789   0.000000   0.017578    0.00000   0.000000   0.000977   \n",
       "9   0.000000   0.070312   0.013672    0.19238   0.000000   0.074219   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "3   0.000000   0.047852  \n",
       "4   0.000000   0.031250  \n",
       "5   0.001953   0.013672  \n",
       "6   0.039062   0.003906  \n",
       "7   0.002930   0.036133  \n",
       "8   0.033203   0.074219  \n",
       "9   0.000000   0.000000  \n",
       "\n",
       "[10 rows x 194 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('input/train.csv',index_col=False)\n",
    "test_data=pd.read_csv('input/test.csv',index_col=False)\n",
    "data.head(10) #Return 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas dataframe to numpy array\n",
    "X_train = data.iloc[:,2:].values\n",
    "Y_train = data.iloc[:,1:2].values\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder=LabelEncoder()\n",
    "# le=encoder.fit(data.species)\n",
    "# labels=le.transform(data.species)\n",
    "# Y_train=np.array(le.classes_)\n",
    "# print(len(Y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=192, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(99, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Acer_Opalus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jun\\Desktop\\PI 3\\DeepLearning.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jun/Desktop/PI%203/DeepLearning.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jun/Desktop/PI%203/DeepLearning.ipynb#ch0000014?line=1'>2</a>\u001b[0m Y_train \u001b[39m=\u001b[39m tensorflow\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mto_categorical(Y_train, \u001b[39m99\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jun/Desktop/PI%203/DeepLearning.ipynb#ch0000014?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, Y_train, epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jun\\anaconda3\\lib\\site-packages\\keras\\utils\\np_utils.py:62\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=20'>21</a>\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.utils.to_categorical\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_categorical\u001b[39m(y, num_classes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=22'>23</a>\u001b[0m   \u001b[39m\"\"\"Converts a class vector (integers) to binary class matrix.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=23'>24</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=24'>25</a>\u001b[0m \u001b[39m  E.g. for use with `categorical_crossentropy`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=59'>60</a>\u001b[0m \u001b[39m  [0. 0. 0. 0.]\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=60'>61</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=61'>62</a>\u001b[0m   y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(y, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=62'>63</a>\u001b[0m   input_shape \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape\n\u001b[0;32m     <a href='file:///c%3A/Users/Jun/anaconda3/lib/site-packages/keras/utils/np_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mif\u001b[39;00m input_shape \u001b[39mand\u001b[39;00m input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(input_shape) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Acer_Opalus'"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "Y_train = tensorflow.keras.utils.to_categorical(Y_train, 99)\n",
    "history = model.fit(X_train, Y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f0d44c8b4baa9375433f27d8eb919c7a09c2a0f4a75c77d53660f1a12b87d70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
